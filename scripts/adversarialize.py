import numpy as np
import pandas as pd
import argparse
import os
import sys
import random
random.seed(100)

from keras.layers import Dense, Conv1D, Activation, GlobalMaxPooling1D, Input, Embedding, Multiply
from keras.models import Model, load_model
from keras.optimizers import SGD
from keras.callbacks import LearningRateScheduler
from keras import backend as K
from keras import metrics
from sklearn.model_selection import train_test_split

padding_char = 256
maxlen = 1048576

def adversarialize_binary(binary, binary_name="", added_bytes=1000, max_iter=100, target_confidence=0.5, output_dir=None):
    if output_dir is None:
        print("Warning: no output directory was specified. Output will only be through the console!")
    sess = K.get_session()

    malconv_dir = '/localhome/jmack2545/ece696b/ember/malconv/'
    if os.path.exists(malconv_dir + 'malconv.h5'):
        print("restoring malconv.h5 from disk for continuation training...")
        model = load_model(malconv_dir + 'malconv.h5')
        _, maxlen, embedding_size = model.layers[1].output_shape
    else:
        print("No existing model found...")
        print(f"Please change the malconv_dir variable to point to the saved model.\nCurrent value is {malconv_dir}")
        print("Adversarial modification unsuccessful")
        sys.exit(1)

    # Build a second representation of the given model, but skip the embedding layer so that we can get gradients from it
    inp2 = Input(shape=(maxlen,8))
    filt2 = Conv1D.from_config(model.layers[2].get_config())(inp2)
    attn2 = Conv1D.from_config(model.layers[3].get_config())(inp2)
    gated2 = Multiply()([filt2, attn2])
    feat2 = GlobalMaxPooling1D()(gated2)
    dense2 = Dense.from_config(model.layers[6].get_config())(feat2)
    outp2 = Dense.from_config(model.layers[7].get_config())(dense2)

    model2 = Model(inp2, outp2)

    model2.layers[1].set_weights(model.layers[2].get_weights())
    model2.layers[2].set_weights(model.layers[3].get_weights())
    model2.layers[3].set_weights(model.layers[4].get_weights())
    model2.layers[4].set_weights(model.layers[5].get_weights())
    model2.layers[5].set_weights(model.layers[6].get_weights())
    model2.layers[6].set_weights(model.layers[7].get_weights())

    model.compile(loss='binary_crossentropy', 
                optimizer=SGD(lr=0.01,momentum=0.9,nesterov=True,decay=1e-3), 
                metrics=[metrics.binary_accuracy])

    model2.compile(loss='binary_crossentropy', 
                optimizer=SGD(lr=0.01,momentum=0.9,nesterov=True,decay=1e-3), 
                metrics=[metrics.binary_accuracy])

    # We need access to the embedding layer during adversarial example generation. Ensure that we're able to get it
    # https://stackoverflow.com/questions/51235118/how-to-get-word-vectors-from-keras-embedding-layer
    embedding_weights = model.layers[1].get_weights()[0]

    adv_pad_bytes = list(map(lambda b: np.uint16(b), [random.randint(0,255) for _ in range(added_bytes)]))

    prev_probs = []
    modified_byte_locations = []
    adv_target = K.ones_like(model2.output)

    pad_byte_locs = np.where(binary[0, :] == padding_char)[0]
    if len(pad_byte_locs) > 0:
        first_pad_byte = min(pad_byte_locs)
    else:
        print("There is no room left to add padding bytes. Unable to modify.")
        print("Adversarial modification unsuccessful")
        sys.exit(1)
    adv_bytes = np.hstack((binary[0, :first_pad_byte], adv_pad_bytes))
    adv_bytes_temp = np.ones((1,maxlen), dtype=np.uint16) * padding_char
    adv_bytes_temp[0][:len(adv_bytes)] = adv_bytes

    loss_keras = -1 * K.binary_crossentropy(adv_target, model2.output)
    grads = K.gradients(loss_keras, model2.input)
    norm_grads = K.l2_normalize(grads[0])

    adv_pred = model2.predict([[embedding_weights[b]] for b in adv_bytes_temp])[0][0]
    print(f"Initial prediction: {adv_pred}")

    t = 0
    while adv_pred < target_confidence and t < max_iter:
        t = t + 1
        print(f"Starting iteration {t}")
        #prev_probs.append(model.predict(adv_bytes_temp)[0][0])
        all_grads_zero = True
        for p in range(added_bytes):
            j = first_pad_byte + p + 1
            # "Compute the gradient w_j = - GRAD_phi(X_j)"     
            # Setup the keras tensors that we'll evaluate to get our normalized gradients
            adv_bytes_temp_emb = [embedding_weights[b] for b in adv_bytes_temp]
            #print(adv_bytes_temp_emb)
            norm_grads_eval = sess.run(norm_grads, feed_dict={model2.input:adv_bytes_temp_emb})
            #print(norm_grads_eval[0, j, :])
            
            # Do the thing
            s_i = None
            d_i = None
            d_i_min = np.inf
            min_byte = None
            for i in range(256):
                m_i = embedding_weights[i]
                z_j = embedding_weights[adv_bytes_temp[0, j]]
                s_i = np.dot(norm_grads_eval[0, j, :], m_i - z_j)
                d_i = np.linalg.norm(m_i - (z_j + (s_i * norm_grads_eval[0, j, :])), ord=2)
                if d_i < d_i_min and s_i > 0:
                    d_i_min = d_i
                    min_byte = i
            #print(f"Finished an inner for-loop and the minimum byte was: {min_byte}")
            if min_byte is not None:
                all_grads_zero = False
                original_byte = adv_bytes_temp[0, j]
                adv_bytes_temp[0, j] = min_byte
                adv_pred = model2.predict([[embedding_weights[b]] for b in adv_bytes_temp])[0][0]
                print(f"An action has been taken: modified byte {j} (byte {p} of the padding) from {original_byte} to {min_byte}")
                print(f"Updated prediction: {adv_pred}")
                prev_probs.append(adv_pred)
                modified_byte_locations.append(j)
            if p > 0 and p % (added_bytes // 5) == 0:
                print(f"{p / added_bytes * 100.0}% done with current iteration")
        if all_grads_zero:
            print("All gradients were 0 in the previous iteration. We are at a fixed point. Exiting early!")
            break

    adv_pred = model2.predict([[embedding_weights[b]] for b in adv_bytes_temp])[0][0]
    
    print("Finished adversarial modification loop.")
    if adv_pred >= target_confidence:
        print("Adversarial modification successful")
        if output_dir is None:
            print(f"List of malware confidence as byte modifications proceeded:\n{prev_probs}")
            print(f"List of modified byte locations:\n{modified_byte_locations}")
        else:
            os.makedirs(os.path.join(output_dir, "successful"), exist_ok=True)
            save_dir = os.path.join(output_dir, "successful")
            np.save(os.path.join(save_dir, binary_name + "_probabilities.npy"), prev_probs)
            np.save(os.path.join(save_dir, binary_name + "_modified_byte_locations.npy"), modified_byte_locations)
            with open(os.path.join(save_dir, binary_name + "_modified.exe"), 'wb') as output_binary:
                output_binary.write(adv_bytes_temp)
            print(f"Output written to {save_dir}")
    else:
        print("Adversarial modification unsuccessful")
        if output_dir is None:
            print(f"List of malware confidence as byte modifications proceeded:\n{prev_probs}")
            print(f"List of modified byte locations:\n{modified_byte_locations}")
        else:
            os.makedirs(os.path.join(output_dir, "unsuccessful"), exist_ok=True)
            save_dir = os.path.join(output_dir, "unsuccessful")
            np.save(os.path.join(save_dir, binary_name + "_probabilities.npy"), prev_probs)
            np.save(os.path.join(save_dir, binary_name + "_modified_byte_locations.npy"), modified_byte_locations)
            with open(os.path.join(save_dir, binary_name + "_modified.exe"), 'wb') as output_binary:
                output_binary.write(adv_bytes_temp)
            print(f"Output written to {save_dir}")
    
def get_arg_parser():
    parser = argparse.ArgumentParser(description='Attempt to convert a given binary to an adversarial binary')
    parser.add_argument('binary', metavar='bin', type=str, help='Path to binary that should be made adversarial')
    parser.add_argument('--pad_bytes', type=int, required=False, default=1000, help='Number of bytes to append and use in adversarial feature crafting')
    parser.add_argument('--max_iter', type=int, required=False, default=100, help='Maximum number of full iterations over the padding bytes to use in adversarial modifications')
    parser.add_argument('--target_confidence', type=float, required=False, default=0.5, help='Target confidence of the adversarial binary')
    parser.add_argument('--output_dir', type=str, required=False, default=None, help='Location to store output products (prediction history, converted binary, etc)')
    return parser

def filename_to_numpy(filename, maxlen):
    b = np.ones((maxlen,), dtype=np.uint16) * padding_char
    try:
        bytez = np.fromfile(open(filename, 'rb'), dtype=np.uint8)
    except IOError:
        print(f"Unable to open file {filename}!")
        return None
    if len(bytez) <= maxlen:
        b[:len(bytez)] = bytez
    else:
        b[:maxlen] = bytez[:maxlen]
    b.shape = (1, b.shape[0])
    return b

if __name__ == "__main__":
    parser = get_arg_parser()
    args = parser.parse_args()

    binary = filename_to_numpy(args.binary, maxlen)
    if binary is None:
        print("Unable get bytes of target binary, exiting...")
        print("Adversarial modification unsuccessful")
        sys.exit(1)
    binary_name = os.path.basename(args.binary)
    print(f"Beginning adversarial modification of {args.binary}")
    if binary_name.endswith(".exe"):
        binary_name = binary_name[:-4]
    print(f"Running with configuration:\nbinary_name:{binary_name}\npad_bytes:{args.pad_bytes}\nmax_iter:{args.max_iter}\ntarget_confidence:{args.target_confidence}\noutput_dir:{args.output_dir}")
    adversarialize_binary(binary, binary_name=binary_name, added_bytes=args.pad_bytes, 
    max_iter=args.max_iter, target_confidence=args.target_confidence, output_dir=args.output_dir)
    sys.exit(0)
